---
title: "Historic Salmon Diet OBIS wrangle"
author: "Tim van der Stap"
date: "9/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

packages <- c("tidyverse", "lubridate", "devtools", "obistools", "readxl", "parsedate", "googledrive", "here")
for (package in packages) {if (!(package %in% install.packages())) {install.packages(package)} 
  else if (package %in% old.packages()) {install.packages(package)} }

library(tidyverse)
library(lubridate)
library(readxl)
library(parsedate)
library(googledrive)
library(here)
library(obistools)
```

In this script we will demonstrate how to read in and standardize, or format, historic salmon diet data to DwC standards so that we can host it on [OBIS](https://obis.org/). In order to do so, we have to create an Event and an Occurrence Core, with specific column headings. This script will illustrate how to create those cores. 

Read in and filter for source_id == 44. I prefer reading in a .csv file rather than an .xlsx file because it seems parsing dates is easier from a .csv file (for some reason the date_min column changed when reading in .xlsx file). The dates have to be changed to iso_8601 format. As stated in the OBIS [manual](https://obis.org/manual/darwincore/#time): _ISO 8601 dates can represent moments in time at different resolutions, as well as time intervals, which use / as a separator. Date and time are separated by T. Times can have a time zone indicator at the end, if this is not the case then the time is assumed to be local time. When a time is UTC, a Z is added._

As no times were recorded in this dataset, no `Z` is added, and any reference to time is removed after formatting to the iso_8601 standard. 

```{r, message = FALSE, warning=FALSE}
source_id_44 <- read_csv(here::here("datasets", "npmsdd_data_from_caroline", "diet_data_0_1.csv")) %>%
  filter(source_id == "44") %>%
  mutate(eventDate = format_iso_8601(as.POSIXct(date_min,
                                                format="%Y-%m-%d"))) %>%
  mutate(eventDate = str_replace(eventDate, "\\T.+", ""))
```

Next we need to create the Event Core. Required columns, as per OBIS, are: `eventDate`, `eventID`. We also need to figure out how to add coordinates to the Event Core, especially given that for predator_id 116:125 the coordinates are those of a polygon (`lat_min`, `lat_max`, `lon_min` and `lon_max` are populated). For all other data entries, only the `lat_min` and `lon_min` are populated, and these will therefore correspond to the OBIS columns of `decimalLatitude` and `decimalLongitude`. Additionally, as per OBIS standards, latitude has to be in the range of -90 to 90, inclusive, and longitude has to be in the range of -180 to 180, inclusive. 

The coordinates for predator_ids 116:125 represent a polygon. The rest are all `POINT` estimates. Furthermore, we want to automate the process where the coordinates of both the `POINT` and `POLYGON` coordinates are provided from the four columns with coordinates. To get more accurate coordinates for the polygon; [this](https://github.com/iobis/obistools#calculate-centroid-and-radius-for-wkt-geometries) is a very useful link!

The string of the polygon can be obtained from a [WKT Tool](https://obis.org/maptool/#). It's easy enough to add in the coordinates into this website, draw the polygon and copy paste the generated WKT into our script here. I would recommend to follow the script below to determine the coordinates of points, especially if data was collected at various different points. The way to depict points, polygons, linestrings, multipolygons etc in the `footprintWKT` differs - see [here](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry). 

Finally, as some data is collected in a polygon, OBIS will want to know what the `coordinateUncertaintyInMeters` is. Thankfully there is a neat package and function for this: `obistools::calculate_centroid()`. 

```{r}
source_id_44 <- source_id_44 %>% 
  mutate(footprintWKT = " ")

for(i in 1:nrow(source_id_44)){
  if (!is.na(source_id_44$lat_max[i])) {
  source_id_44$footprintWKT[i] <- "POLYGON"
} else {
  source_id_44$footprintWKT[i] <- "POINT"
}
}

source_id_44$lon_min[source_id_44$lon_min>0] = source_id_44$lon_min[source_id_44$lon_min>0] - 360
if(source_id_44$lon_max > 0){
  source_id_44$lon_max <- source_id_44$lon_max - 360
}

# Rename some columns to fit DwC standards. 
source_id_44 <- source_id_44 %>% 
  dplyr::rename(year = year_min,
                month = month_min)

source_id_44$footprintWKT <- with(source_id_44, ifelse(footprintWKT == "POINT", paste0("POINT", " (", lon_min," ",
                                                                                     lat_min, ")"), 
paste0("POLYGON ((-180.00000 65.00000, -180.00000 35.00000, -125.00000 35.00000, -125.00000 65.00000, -180.00000 65.00000))")))

# Find decimalLongitude, decimalLatitude and coordinateUncertaintyInMeters using obistools, and then join these columns to the source_id_44 dataframe. 
coordinates <- obistools::calculate_centroid(source_id_44$footprintWKT)
source_id_44 <- cbind(source_id_44, coordinates)
```

Additionally, an `eventID` column has to be created, which will be a unique identifier following the structure: database - source_id - predator_id. For this data standardization, we follow the format as demonstrated [here](http://ogc-act.csiro.au/ipt/resource?r=csiro_sef_diet), however this could change as the workflow for OBIS changes. 

Following this example, we create a prey event core and predator Event core, and join these together so that all required information in the final event core is listed in all the rows. Given that the database has numerous columns, we select only the ones that are relevant in the Event Core. We use the `distinct()` function on selected columns to filter for unique capture events. 

Finally, add a column `geodeticDatum`. As stated in OBIS _the spatial reference system to be documented in `geodeticDatum` is `EPSG:4326`_. Additionally, it would be beneficial to provide a link to the DOI (if the paper has one - otherwise perhaps one should be created) in the column `samplingProtocol`.

```{r}
predator <- source_id_44 %>%
  mutate(eventID = paste("npmsdd", source_id, predator_id, sep = "-"))

prey <- source_id_44 %>%
  mutate(eventID = paste("npmsdd", source_id, predator_id, sep = "-")) %>%
  pivot_longer(cols = Actinopterygii:Pteropoda,
               names_to = "prey",
               values_to = "presence")

HS_44 <- full_join(predator, prey) # We need this data frame for our occurrence core later.
hs_44_event <- HS_44 %>%
  select(eventID, eventDate, year, month, decimalLatitude, 
         decimalLongitude, footprintWKT, coordinateUncertaintyInMeters) %>%
  distinct() %>%
  mutate(type = "Event",
         geodeticDatum = "EPSG:4326",
         samplingProtocol = " ")

write_csv(hs_44_event, here::here("datasets", "npmsdd_data_from_caroline", "hs_44",
                                  "hs_44_event.csv"))
```

***

Additionally, following the previously mentioned example, we are required to make a resourceRelationship table, as both the salmon and the stomach content can be viewed as species occurrences. All salmon individuals in this regard are considered the predators, as indicate with a _p_. Prey species found in the stomach content will be indicated by _pr_. We want to make it such that if multiple species of prey are present (i.e., '1'), they will be assigned, in ascending order, pr1, pr2, independent of exactly which species were found in the stomach content.

The resourceRelationshipID follows the format of e.g. `npmsdd-44-116-ppr1`, `npmsdd-44-116-ppr2` etc. In other words, database - source_id - predator_id - predatorprey1 etc. Some salmon individuals have more than 1 identified prey spp in their stomach. 

**IMPORTANT** In the example scripts, I noticed a column `id` - please note that this is **NOT** the same as the eventID, it's the id the IPT uses as the id for each row in the dataset, so it's not a column that has to be populated in the relationship or occurrence core. 

```{r resourceRelationship}
prey$id <- " " # create a dummy column to populate
prey <- prey %>%
  filter(presence == "1")
for(i in unique(prey$eventID)) {
  prey$id[prey$eventID == i] <- seq_len(sum(prey$eventID == i))
}

prey$prey_id <- paste0("pr", prey$id)

resourceRelationshipID <- paste(prey$eventID, "p", sep = "-")
resourceRelationshipID <- paste0(resourceRelationshipID, prey$prey_id)
resourceID <- paste(prey$eventID, "p", sep = "-")
relatedResourceID <-  paste(prey$eventID, prey$prey_id, sep = "-")
relationshipOfResource <- "hasEaten"

hs_44_resourcerelationship <- cbind(resourceRelationshipID, resourceID, relatedResourceID, relationshipOfResource) %>% as.data.frame()

write_csv(hs_44_resourcerelationship, here::here("datasets", "npmsdd_data_from_caroline", "hs_44",
                                  "hs_44_resourcerelationship.csv"))
```

***

Next, we create the Occurrence Core, where we add the WoRMS URN to not just the salmon but also the species identified in their stomachs. 

``` {r prey_occurrence}
# create two separate data frames of occurrences, one for the prey species (stomach content) and one for the predator (salmon) species, and then later merge these two data frames. The first step for our prey_occurrence core is to filter for the species found in the stomach (i.e., that have a prey_id)

prey_occ <- HS_44 %>% filter(presence == "1") %>%
  select(eventID, prey, presence) %>%
  dplyr::rename(scientificName = prey) %>%
  mutate(occurrenceStatus = "present",
         occurrenceID = paste(eventID, prey$prey_id, sep = "-"))

# Perhaps we shouldn't remove the kingdom, phylum and infraorder classes in the initial data wrangling process, because those columns can be included in the Occurrence Core (line #184). 

prey_occ <- prey_occ %>%
  mutate(scientificNameID = case_when(
    scientificName == "Actinopterygii" ~ "urn:lsid:marinespecies.org:taxname:10194",
    scientificName == "Amphipoda" ~ "urn:lsid:marinespecies.org:taxname:1135",
    scientificName == "Anomura" ~ "urn:lsid:marinespecies.org:taxname:106671",
    scientificName == "Brachyura" ~ "urn:lsid:marinespecies.org:taxname:106673",
    scientificName == "Callianassa" ~ "urn:lsid:marinespecies.org:taxname:107072",
    scientificName == "Chaetognatha" ~ "urn:lsid:marinespecies.org:taxname:2081",
    scientificName == "Coleoidea" ~ "urn:lsid:marinespecies.org:taxname:11709",
    scientificName == "Copepoda" ~ "urn:lsid:marinespecies.org:taxname:1080",
    scientificName == "Crustacea" ~ "urn:lsid:marinespecies.org:taxname:1066",
    scientificName == "Euphausiacea" ~ "urn:lsid:marinespecies.org:taxname:1128",
    scientificName == "Euphausiidae" ~ "urn:lsid:marinespecies.org:taxname:110671",
    scientificName == "Limacina" ~ "urn:lsid:marinespecies.org:taxname:138122",
    scientificName == "Limacina helicina" ~ "urn:lsid:marinespecies.org:taxname:140223",
    scientificName == "Miscellaneous" ~ " ",
    scientificName == "Polychaeta" ~ "urn:lsid:marinespecies.org:taxname:883",
    scientificName == "Pteropoda" ~ "urn:lsid:marinespecies.org:taxname:325345")
  ) %>%
  select(eventID, scientificName, scientificNameID, occurrenceStatus, occurrenceID) %>%
  filter(occurrenceStatus == "present")
```

And to create the predator_occ core:

``` {r predator_occ}
# Filter for the predator species, i.e. ones that don't have a prey_id. 
predator_occ <- HS_44 %>% filter(presence == "1") %>%
  select(eventID, predator_lowest_taxonomic_level, 
         predator_maturity, predator_sex, predator_replicates, presence) %>%
  dplyr::rename(scientificName = predator_lowest_taxonomic_level) %>%
  mutate(occurrenceStatus = "present",
         occurrenceID = paste(eventID, "p", sep = "-")) %>%
  distinct() %>%
  mutate(scientificNameID = case_when(
    scientificName == "Oncorhynchus keta" ~ "urn:lsid:marinespecies.org:taxname:127183",
    scientificName == "Oncorhynchus nerka" ~ "urn:lsid:marinespecies.org:taxname:254569",
    scientificName == "Oncorhynchus gorbuscha" ~ "urn:lsid:marinespecies.org:taxname:127182",
    scientificName == "Oncorhynchus kisutch" ~ "urn:lsid:marinespecies.org:taxname:127184",
    scientificName == "Oncorhynchus mykiss" ~ "urn:lsid:marinespecies.org:taxname:127185")
  ) %>%
  dplyr::rename(lifeStage = predator_maturity,
                sex = predator_sex,
                organismQuantity = predator_replicates) %>%
  mutate(organismQuantityType = "individuals") %>%
  select(eventID, occurrenceID, scientificName, scientificNameID, sex, lifeStage, occurrenceStatus,
         organismQuantity, organismQuantityType)
```

Join the two occurrence cores. As per OBIS, _if `basisOfRecord` is `PreservedSpecimen`, please also add the `institutionCode`, `collectionCode` and `catalogNumber` which will enable people to visit the collection and re-examine the material_. However, I don't know if these columns can be populated arbitrarily. Additionally, I'd say that as we're talking about a preserved specimen, the `preparations` column also has to be populated. 

``` {r occ}
hs_44_occ <- bind_rows(prey_occ, predator_occ)

# To re-order the eventID, use following code:
order <- stringr::str_sort(hs_44_occ$occurrenceID, numeric=TRUE)
hs_44_occ <- hs_44_occ[match(order, hs_44_occ$occurrenceID),]

# As basisOfRecord is `PreservedSpecimen`, it is recommended that we add `institutionCode`, `collectionCode` and `catalogNumber`. 
hs_44_occ <- hs_44_occ %>%
  mutate(basisOfRecord = "PreservedSpecimen",
         institutionCode = " ",
         collectionCode = " ", 
         catalogNumber = " ",
         preparations = " ")

write_csv(hs_44_occ, here::here("datasets", "npmsdd_data_from_caroline", "hs_44",
                                  "hs_44_occ.csv"))

# The `obistools::flatten_occurrence(hs_44_event, hs_44_occ)` does not seem to be working, because it is missing parentEventID. In most of the datasets that I've wrangled there is a parentEventID, but with historic salmon I haven't this because I don't know what the common parentEventID would be for data associated to both salmon (predator) and it's stomach content (prey). Therefore, should the event and occurrence cores need to be combined, use:

hs_44_fnl_event_occ <- left_join(hs_44_event, hs_44_occ, by = "eventID")

write_csv(hs_44_fnl_event_occ, here::here("datasets", "npmsdd_data_from_caroline", "hs_44",
                                          "hs_44_event_occ.csv"))
```

I want to add in some fail-safes to ensure that we have required information for OBIS. Below are listed some of the functions from the `obistools` package that can be used to QC the formatted data. To see what these different functions do, see [obistools](https://github.com/iobis/obistools).

``` {r fail-safe_QC}
obistools::check_eventdate(hs_44_event) #
obistools::check_extension_eventids(hs_44_event, hs_44_occ)
obistools::check_eventids() 
obistools::match_taxa(hs_44_occ$scientificName) 
obistools::check_fields(hs_44_occ) 
obistools::check_fields(hs_44_fnl_event_occ)
```

To get a nice visual and see if perhaps some of the coordinates are wrong/off, we can plot the occurrences in a map or leaflet, and also perform checks to see if the data isn't on land when it should be in the ocean, or whether the depths are off.

As the depth of the occurrence was not recorded, no depth checks can be done (for this specific dataset). As a fun little bonus, I've added salmon icons to the map and the script on how to add these to e.g. a leaflet map. The icons are from [phylopic](http://phylopic.org/).

``` {r maps_and_checks}
# The images for salmon come from phylopic.org
salmon <- leaflet::makeIcon("images/salmon_tiny.png",
                            "images/salmon_small.png", 26, 14)

obistools::plot_map(hs_44_fnl_event_occ, zoom = TRUE) # plot points on ggplot2 map
salmon_leaflet <- obistools::plot_map_leaflet(hs_44_fnl_event_occ) %>%
  setView(median(hs_44_fnl_event_occ$decimalLongitude), median(hs_44_fnl_event_occ$decimalLatitude), zoom = 4) %>%
  addTiles() %>%
  addMarkers(hs_44_fnl_event_occ$decimalLongitude, 
             hs_44_fnl_event_occ$decimalLatitude, icon = salmon) # plot points on leaflet map. 
salmon_leaflet 

obistools::check_onland(hs_44_fnl_event_occ)

obistools::plot_map(check_depth(data, depthmargin = 50), zoom = TRUE)
report <- obistools::check_depth(data, report = TRUE, depthmargin = 50)

# The depthmargin indicates how much the given depth can deviate from the bathymetry in the rasters. 
```

To save any maps etc, use the following chunk of code:

``` {r save_plots_images}
obistools::plot_map(hs_44_fnl_event_occ, zoom = TRUE)
ggsave(here::here("datasets", "npmsdd_data_from_caroline", "hs_44", "map_hs_44.png"))
```