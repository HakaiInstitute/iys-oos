---
title: "GoA 2020 Bongo"
author: "Tim van der Stap"
date: "12/1/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(tidyverse)
library(lubridate)
library(dplyr)
library(obistools)
library(taxizesoap)
library(readxl)
library(parsedate)
library(googledrive)
library(here)
```

## Getting started

The following line only needs to be run once to download the tidied data from Google Drive to your computer's hard drive

```{r drive_download}
# Make sure your folder path exists already (e.g. ./POM/raw_data)
drive_download("https://docs.google.com/spreadsheets/d/1DGyFTMc1jUmrKsAnH_17GiAbstMO0uYc/edit#gid=1513148710", path = here("Zooplankton - Bongo", "raw_data", "Bongo.xlsx"), overwrite = TRUE)
```

Now we need to read in the Excel file and the correct sheets we want to work with. In the Excel file there are two sheets that we want to work with, one that includes the metadata, whereas the other sheet includes taxonomic occurrences of zooplankton in the bongo net. 

``` {r read_file}
bongo2020_metadata <- read_excel(here("Zooplankton - Bongo", "raw_data", "Bongo.xlsx"), sheet = "Bongo metadata")
bongo2020_data <- read_excel(here("Zooplankton - Bongo", "raw_data", "Bongo.xlsx"), sheet = "Animal samples")
```

Next we start with creating the Event Core for this Bongo dataset. 

``` {r bongo2020}
bongo2020 <- bongo2020_data %>% filter(Gear == "Bongo") %>%
  mutate(cruise = "GoA2020",
         station = paste(cruise, Station, sep = "_Stn:"),
         cast = paste(station, Net, sep = ":bongo:Net"))

bongo2020_event <- bongo2020_metadata %>%
  mutate(Time = format(Time, "%H:%M:%S"),
         eventDate = format_iso_8601(as.POSIXct(paste(Date, Time), 
                                                format = "%Y-%m-%d %H:%M:%S",
                                                # Time is recorded in PDT, must ensure that timezone is correct
                                                tz = "Asia/Kamchatka")),
         eventDate = str_replace(eventDate, "\\+00:00", "Z"),
         cruise = "GoA2020",
         station = paste(cruise, Station, sep = "_Stn:"),
         cast = paste(station, `Net number`, sep = ":bongo:Net"))
```

## Event Core

``` {r bongo2020_event}
bongo2020_cruise <- bongo2020_event %>%
  select(eventID = cruise) %>%
  distinct(eventID) %>%
  mutate(eventRemarks = "cruise")

bongo2020_station <- bongo2020_event %>%
  select(eventID = station,
         parentEventID = cruise) %>%
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(eventRemarks = "station")

bongo2020_cast <- bongo2020_event %>%
  select(eventID = cast,
         parentEventID = station,
         eventDate,
         decimalLatitude = Latitude,
         decimalLongitude = Longitude,
         minimumDepthInMetres = `Sample depth_m`,
         maximumDepthInMetres = `Sample depth_m`,
         sampleSizeValue = `Flowmeter Volume Filtered_m3`) %>%
  mutate(sampleSizeUnit = "m^3",
         samplingProtocol = "vertical Bongo Net deployment",
         samplingEffort = "Volume sea water filtered") %>%
  distinct(eventID, .keep_all = TRUE) %>%
  mutate(eventRemarks = "cast")

bongo2020_cast <- bongo2020_cast %>%
         mutate(footprintWKT = paste("POINT"," (", bongo2020_cast$decimalLongitude, " ", 
                                     bongo2020_cast$decimalLatitude, ")"))

coordinates <- obistools::calculate_centroid(bongo2020_cast$footprintWKT) %>% select(coordinateUncertaintyInMeters)
bongo2020_cast <- cbind(bongo2020_cast, coordinates)

bongo2020_event <- bind_rows(bongo2020_cruise,
                             bongo2020_station,
                             bongo2020_cast) %>% 
  mutate(type = "HumanObservation",
         geodeticDatum = "EPSG:4326 WGS84")

# Check to make sure that all parentEventIDs have a corresponding eventID, and then flatten the data:
obistools::check_eventids(bongo2020_event)
bongo2020_event <- obistools::flatten_event(bongo2020_event)

# Make sure the folder path exists already (e.g. ./Bongo/tidy_data)
write_csv(bongo2020_event, here("Zooplankton - Bongo", "tidy_data", "bongo2020_event.csv"))
drive_upload(here("Zooplankton - Bongo", "tidy_data", "bongo2020_event.csv"),
             path = " ",
             name = "bongo2020_eventCore.csv",
             overwrite = TRUE)
```

Now that the event core has been created, next we focus on the occurrence core. The main question that we have to answer to finalize this core is:

- [ ] If a data entry cannot have an associated scientificName and scientificNameID (required terms), should they still have an associated occurrenceID? This is the case for Zooplankton: perhaps this should be classified as verbatimScientificName?

Similar to what was done for the 2019 data, we need to ensure that all recorded data have their own row. What I mean by this, is that for some Sample IDs there are numerous length measurements, and a number > 1. These have to get their own data entry row. 

``` {r bongo2020_occ, eval = FALSE}
unique(bongo2020$Species)

# Identify all entries that would not have an WoRMS URN associated to it:

bongo2020_occ_spp <- bongo2020 %>% filter(!(Species %in% c("Whole net", "Size fraction", "Gelatinous spp.", "Jelly (unknown)")))
```

Manual inspection of the `bongo2020_occ_spp` dataframe indicates that, although there are some data entries where an alternative species is mentioned in the notes, all of these data entries do have species names associated to them. Therefore we don't have to manually change the species' name for these entries (this was the case for some entries in the 2019 bongo data). Additionally, manual inspection indicated that there are _no_ approximate values in the `Number` column (i.e., ~3, >4). 

Next we confirm that there are currently no duplicate Sample IDs in the dataframe. Once we have that confirmed, we filter for all the data entries where Number > 1 _and_ where no length range is provided. Manual inspection showed that if multiple length_mm measurements are provided, the number of length measurements provided always matched the value in the `Number` column. These entries will either have to separated into their own row with associated lenght/weight measurement. 

If a length range is provided, these data entries will need a minimumLength and maximumLength associated in the eMOF core. 

``` {r, eval = FALSE}
bongo2020_occ_spp[duplicated(bongo2020_occ_spp$`Sample ID`),] # no rows in this dataframe = no duplicates.

# Filter out the data entries where Number > 1, and where individual length measurements are provided in the length_mm column. These data entries will be treated separately and then merged back into the larger dataframe. 

bongo2020_pre_occ <- bongo2020_occ_spp %>% filter(Number > 1)
bongo2020_pre_occ1 <- bongo2020_pre_occ[grepl(",", bongo2020_pre_occ$Length_mm),]

bongo2020_occ1 <- bongo2020_pre_occ1 %>%
  mutate(Length_mm = strsplit(Length_mm, ", ")) %>%  unnest(Length_mm) %>%
  group_by(`Sample ID`) %>%
  mutate(count = seq_len(length(`Sample ID`)),
         `Sample ID` = paste(`Sample ID`, count, sep = "-"),
         Number = 1) %>%
  select(-count)

# These two dataframes will be joined, and then merged back into a dataframe (that was initially subsetted for any data entries where Number > 1). 

bongo2020_occ <- bongo2020_occ_spp[!(bongo2020_occ_spp$`Sample ID` %in% bongo2020_pre_occ1$`Sample ID`),]
bongo2020_occ <- rbind(bongo2020_occ, bongo2020_occ1)
bongo2020_occ <- bongo2020_occ[order(bongo2020_occ$Station),]

bongo2020_occ <- bongo2020_occ %>%
  rename(organismQuantity = Number) %>%
  mutate(organismQuantityType = "individuals",
         occurrenceID = paste(cast, `Sample ID`, sep = ":"),
         occurrenceStatus = "present")

# Next, we start the taxon matching procedure by passing our scientific names to the match_taxon() function:

Species <- unique(bongo2020_occ$Species)
scientificNames <- obistools::match_taxa(Species)
scientificNames <- cbind(Species, scientificNames)

# Merge this dataframe with the original occurrence dataframe:

bongo2020_occ <- left_join(bongo2020_occ, scientificNames, by = "Species")

# Use taxizesoap() package to derive the taxonomic data from the WoRMS-corrected scientificNames. Rename lsid to scientificNameID because we'll need that to merge the dataframe back with the original in the next step:
names_worms <- taxizesoap::worms_records(bongo2020_occ$scientificName) %>%
  select(inputid, scientificname, authority, rank, valid_name, valid_authority, kingdom, phylum,
         class, order, family, genus, lsid) %>% rename(scientificNameID = lsid)

# Merge back with original dataframe:
bongo2020_occ_full <- left_join(bongo2020_occ, names_worms, by = "scientificNameID") %>% distinct()

# As you can see there are still rows where no taxonomic data is provided for the scientificName. This is for data entries such as "Squid" and "Fish eggs". 

Species_manual <- bongo2020_occ_full[is.na(bongo2020_occ_full$scientificName),]
Species_manual <- Species_manual %>%
  mutate(kingdom = case_when(
    Species == "Squid" ~ "Animalia",
    Species == "Fish egg" ~ "Animalia"),
    phylum = case_when(
      Species == "Squid" ~ "Mollusca",
      Species == "Fish egg" ~ "Chordata"),
    class = case_when(
      Species == "Squid" ~ "Cephalopoda"),
    scientificName = case_when(
      Species == "Squid" ~ "Cephalopoda",
      Species == "Fish egg" ~ "Pisces"),
    scientificNameID = case_when(
      Species == "Squid" ~ "urn:lsid:marinespecies.org:taxname:11707",
      Species == "Fish egg" ~ "urn:lsid:marinespecies.org:taxname:11676"))

# Remove the data entries for 'Squid' and 'fish egg' from the original occurrence core, and then add the dataframe `Species_manual` to the `bongo2020_Occ_full`. 
stripped <- bongo2020_occ_full[!bongo2020_occ_full$Species %in% c("Squid", "Fish egg"),]
bongo2020_occ_core <- rbind(stripped, Species_manual) %>%
  select(cast, occurrenceID, occurrenceStatus, scientificName, scientificNameID, authority, kingdom, 
         phylum, class, order, family, genus, Stage, organismQuantity, organismQuantityType) %>%
  rename(eventID = cast)

# You'll notice how both scientificName and valid_name are both in there. This is because some names under scientificName are not accepted under WoRMS, in which case the accepted version is mentioned under valid_name. However, the scientificNameID still references the unaccepted version so this will need to be changed! 

# To see if there are any data entries where valid_name differs from the scientificName (QC for the accuracy of the reported species data):
difference <- bongo2020_occ_full %>% filter(!valid_name == scientificName)

# Make sure the folder path exists already (e.g. ./Bongo/tidy_data)
write_csv(bongo2020_occ_core, here("Zooplankton - Bongo", "tidy_data", "bongo2020_occurrence.csv"))
drive_upload(here("Zooplankton - Bongo", "tidy_data", "bongo2020_occurrence.csv"),
             path = " ",
             name = "bongo2020_occCore.csv",
             overwrite = TRUE)
```